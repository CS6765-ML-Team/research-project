\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\begin{document}

\section{History of Machine Learning in Medicine}

The medical industry revolves around the collection of data and using that data to make diagnoses to save lives. As such, the application of a tool like machine learning, where learning from data is the focus, is clear in such an industry where data collection is so incredibly important. The history of artificial intelligence and machine learning in medicine spans many decades. Periods of rapid innovation followed by periods of AI "Winters" define this history; however, it begins with the centralization and digitization of medical data that would help propel the research and development of the first prototype medical AI systems.

\subsection{A Medical Library for Machines}

During the beginning of research into AI's potential application in the field of medicine, many issues were raised in regards to how the AI models could be used effectively. The two primary issues were 1) how to connect electronic health records and clinical documentation from around the world, and 2) how can a machine understand the underlying knowledge required for operation in a field as complex and critical as medicine~\cite{kulikowski_beginnings_2019}. Work towards solving these problems began in the 1960's at the National Library of Medicine (NLM), where the Medical Literature Analysis and Retrieval System (MEDLARS), and its web-based search engine, PubMed, would be developed and provide access to the world's largest repository of biomedical literature~\cite{kulikowski_beginnings_2019}. This, alongside the NLM's support of capturing and computationally representing medical terminologies and vocabularies~\cite{kulikowski_beginnings_2019}, essentially solved both of the aforementioned problems. There was now access to the medical data required to train an AI system, and there now existed a computational representation of medical vocabulary and knowledge required for an AI system to confidently operate in the field. It should be noted that the development of these tools was not specifically done for the advancement of AI in medicine; nonetheless, they would prove to be essential in the decades to come.

\subsection{The First AI Winter}

What followed in the 1970's is what many refer to as the first "AI Winter", where there was a significant decrease in interest and investment into the field of AI, not just AI in medicine. Many believe the cause of this first winter to be due to the perceived limitations of artificial intelligence at the time~\cite{kaul_history_2020}, forcing people to disregard the field when in reality it was still in its infancy. Despite this deceleration in research, the 1970's still represented a major stepping stone in the use of AI in medicine. This was accomplished through collaboration between universities across the United States and facilitated by an inter-university time-shared computer system based at Stanford called SUMEX-AIM (Stanford University Medical Experimental - AI in Medicine) developed in 1973~\cite{kulikowski_beginnings_2019}. This collaboration allowed for discussions on many of the concerns that AI's involvement in medicine presented at the time, as well as provided a breeding ground for innovative approaches to the newly developing field. 

\subsection{The First Successful Prototype Systems}

Throughout and following the collaborative innovation of the 1970's was the development of three majorly successful prototype AI systems used for medical diagnosis. These three systems, which will be explained and discussed in this section, provided an idea of what was possible with AI and laid the groundwork for AI's future involvement in the medical field.

\subsubsection{MYCIN}

MYCIN, developed in the 1970's, was a rule-based AI system that used a knowledge-base of roughly 600 rules~\cite{kaul_history_2020} to identify infectious diseases a patient may have and then suggest antibiotic treatment tailored to the patient. Physicians would interface directly with the system by inputting the patient's information and MYCIN would output a list of potential infections, as well as their respective treatments based on information provided about the patient. The list produced by MYCIN was achieved through backward chaining, where MYCIN would start with a given infection and work backwards to try to match it to the patient's symptoms, and used a confidence factor representation to measure clinical uncertainty between the potential diagnoses~\cite{kulikowski_beginnings_2019}. Although this inference method and confidence factor is akin to calculating a probability for a given diagnosis being the correct one, the confidence-factor representation was actually found to psychologically aid in accepting MYCIN consultations~\cite{kulikowski_beginnings_2019}. MYCIN demonstrated that early AI systems had the potential to seriously improve the diagnosis process in medicine, even if only confined to hyper-specific subdomains of the field. Dr. Casimir Kulikowski, one of the authors of CASNET, went on to state that MYCIN "was the most influential expert system that demonstrated the power of modularized rules for representing decision-making"~\cite{kulikowski_beginnings_2019}. The work done on MYCIN and the results it demonstrated would go on to encourage researchers in the field to create more AI prototype systems to aid in diagnosis within different subdomains of medicine, Dr. Kulikowski and his system CASNET being the next one.

\subsubsection{CASNET}

The Causal Associational Network (CASNET) was a consultation program designed specifically for glaucoma patients developed at Rutgers University in the 1970's. CASNET used causal explanations of disease, alongside empirical knowledge of presumptive diagnoses, prognoses, and treatments to advise glaucoma patients~\cite{kulikowski_beginnings_2019}. The CASNET model was divided into three programs~\cite{kaul_history_2020}: model-building, consultation, and a maintained database. By applying disease specific information to a patient of interest, CASNET could provide physicians with patient specific care advice. CASNET was unveiled at the Academy of Ophthalmology meeting in Las Vegas, Nevada in 1976~\cite{kaul_history_2020}.

\subsubsection{INTERNIST-I}

Whereas MYCIN and CASNET were designed to be applied in only small, hyper-specific subdomains of medicine, INTERNIST-I was a system developed to cover a broad range of different medical diagnoses within internal medicine. Developed at the University of Pittsburgh by AI researcher Harry Pople and medicine specialist Dr. Jack Myers~\cite{kulikowski_beginnings_2019}, INTERNIST-I was a prototype AI system designed to assist in general internal medicine diagnosis by modeling the expertise of Dr. Myers~\cite{wolfram_appraisal_1995}. Due to the estimated size of the internal medicine field and the number of diseases it contains, designing a system that could confidently classify symptoms and provide correct diagnoses was a monumental task. Development of INTERNIST-I and its accompanying knowledge-base began in the 1970's, and by 1988 the knowledge-base had grown to contain roughly 600 diseases and represented about 25 person-years of effort~\cite{wolfram_appraisal_1995}. This massive knowledge-base would mean INTERNIST-I would have difficulty with complex diagnosis, when there wasn't a single, clear answer. Despite this drawback, INTERNIST-I would demonstrate that the diagnosis process could be broken down into a pure classification problem, instead of the probabilistic models used by MYCIN and CASNET. As such, INTERNIST-I is considered a crucial step in the development of early AI systems in medicine.

\subsection{The First AI Algorithms}

The advent of AI in medicine provided a training ground to validate the usefulness of the different AI algorithms that had already been established at the time. By observing the impact a training algorithm has in a complicated field such as medicine, researchers would be able to judge how useful the algorithm could be in the greater AI landscape. Focusing only on medical diagnosis at the time of the first AI prototype systems discussed above, there existed two primary AI algorithms being employed: decision trees and Bayesian classification.  

\subsubsection{Decision Trees}
In a medical diagnosis, it is up to the diagnostician to use the patient's symptoms to iteratively rule out possible causes until the final diagnosis is reached. As such, the use of decision trees and decision rules to narrow down a medical diagnosis makes intuitive sense, and early researchers agreed with this. Decision trees were considered to be the most promising area for medical data analysis within a potential AI system~\cite{kononenko_machine_2001}. This promise was further amplified with the invention of the Iterative Dichotomizer 3 (ID3) decision tree algorithm and its application in oncological diagnosis~\cite{kononenko_machine_2001}. Decision trees continued to be a popular option for medical diagnosis due to their more easily interpretable structure. This allowed for the algorithm to better explain its inductive reasoning, re-assuring the physician and the patient on the diagnosis~\cite{kononenko_machine_2001}. 

\subsubsection{Bayesian Classification}
Bayesian classification is a probabilistic approach to inference that uses Bayes' theorem to calculate how likely a given hypothesis is. This naturally maps to the world of medical diagnosis, as given a list of patient symptoms, a Bayesian model assigns probabilities to each potential diagnosis, similar to a physician. Although the transparency, or ability to explain its reasoning through its representation, of Bayesian classification was a cause for concern early on, it was found that using Bayesian classifiers far outperformed other AI algorithms in medical diagnostic tests~\cite{kononenko_machine_2001}. With improvements to the issue of transparency addressed in the 1990's~\cite{kononenko_machine_2001}, Bayesian classification became a commonly used approach in the realm of AI medical diagnosis systems.  

\newpage

\section{Machine Learning for Antimicrobial Resistance Predictions}

Antimicrobial resistance (AMR) occurs when microbes dangerous to humans and other living creatures evolve and develop resistances to the drugs that are used to combat these microbes. According to the World Health Organization (WHO), AMR and drug-resistant infections are a major threat to global health, with AMR-related deaths projected to reach roughly 10 million by 2050~\cite{balkhy_amr_2021}. As such, AMR is an active area of research as the global health community works to predict, identify, and prevent AMR cases around the world. Innovations in the fields of artificial intelligence (AI) and machine learning (ML) have allowed for their application in the fight against AMR as prediction and decision support systems. This section is a case study on how AI and ML is successfully being applied in the AMR medical field and the results it is yielding.

\subsection{Application of ML in AMR Prediction}

An important step in tackling AMR and drug-resistant infections is identifying resistant pathogens before they have the ability to cause harm. As such, ML is being applied in the classification and identification of potential drug-resistant pathogens through the analysis of their gene contents. The gene contents of available pathogen genomes can be used to predict resistances of those pathogens to various different antibiotics~\cite{kim_machine_2022}. Classification is a common problem solved by AI and ML, hence its usefulness in this area. Training of these predictive models that will be tasked with classifying potentially drug-resistant genomes is accomplished through supervised learning, where genomes that are already labeled as drug-resistant or non-drug-resistant are used to train and test the accuracy of the model. In the context of AMR, there is already an abundance of identified drug-resistant and non-drug-resistant pathogen genomes, as such these pre-labeled genomes are used for training~\cite{kim_machine_2022}.

As with all applications of ML, it is critical that the trained model generalizes well to data it has not seen before. In the context of AMR predictions, this can be a challenge due to several factors surrounding the genomic data sets. First of all, the location, time, and habitat from which samples are taken matters greatly as samples with similar factors can produce large sets of similar genomes, causing a confounding effect in the ML model~\cite{kim_machine_2022}. In addition to this, it is common for genetic data sets to posses an uneven distribution of AMR phenotypes~\cite{kim_machine_2022}, leading to a model incorrectly classifying the majority of examples as the AMR phenotype of majority. Finally, a major difficulty affecting ML model generalization is the potential for poor or contaminated genome assemblies~\cite{kim_machine_2022}. Contaminated data may introduce false positives into the classification process, incorrectly training the model, and resulting in a model that generalizes poorly with non-contaminated data. Given the above reasons, researchers in the field of AMR believe that no single, universal AMR ML model can generalize perfectly and predict drug-resistance in any given pathogen. As such, ML in AMR prediction is being applied in much more specific cases where prediction models are looking to classify genomic data from specific environments or sample cultures as to reduce the confounding effects discussed above~\cite{kim_machine_2022}. I believe that this idea extends past AMR prediction and into the general methodology seen in ML training. Modeling a subset of a given problem is not only easier and far more reasonable, but it can also yield far higher accuracy and potentially provide more utility than a universal solution.

\subsection{ML Algorithms Employed in AMR Prediction}

As was discussed above, AMR prediction is a classification problem in the context of ML. There exists a plethora of classification algorithms commonly used in ML, and many of these have seen application in AMR prediction studies. Gerontini et al~\cite{gerontini_predictions_2011} developed a system to early detect special cases of antibiotic resistance occurring in hospitals through the the use of the Naive Bayes classifier, Support Vector Machines (SVMs), and the C4.5 classification algorithm. This study, which looked to not only solve an AMR related issue but also compare ML classifiers, found that SVMs achieved the best results when compared to the other algorithms according to each test's F-score~\cite{gerontini_predictions_2011}, however this is only in the context of the problem being solved. Sousa et al.~\cite{sousa_validation_2019} employed a decision tree (DT) algorithm to predict a patient's likelihood of infection with a $\beta$-lactamase, an enzyme which renders certain antibiotics inefective, producing organisms. DTs are a very popular classification algorithm employed in the field of AMR prediction, with Goodman et al.~\cite{goodman_predicting_2019} also using DTs to predict the probability of carbapenem-resistant organisms colonization. Y. Kherabi et al.~\cite{kherabi_machine_2024} performed a review of 36 AMR studies where ML models were being applied and found that 42\% of those studies used DTs and 36\% used a derivative of DTs, Random Forests (RF).  

An important factor that impacts the ML classification algorithm chosen is its transparency. As with all ML applications in the field of medicine, ML algorithms applied in the field of AMR must be able to explain their reasoning behind a prediction. Physicians and researchers will not blindly trust the judgment of a model, especially when human health is involved, as such the model's results must be interpretable. Kim et al.~\cite{kim_machine_2022} defines three aspects of interpretability relevant to AMR predictions: ability to evaluate individual input features, traceability, and the ability to assess the interactions of features. The reason why DTs are so popular within this field is due to the fact that they satisfy the above three aspects of interpretability. DTs can rank the important of training features by identifying features that reduce variance~\cite{kim_machine_2022}, and the hierarchical structure of DTs naturally allows for a model's decision path to be traced through each node of the tree. As a result, DTs provide an intuitive explanation to the classification process, making them an excellent algorithm of choice for AMR predictions. 

\subsection{Implications of ML in AMR Prediction}

The threat presented by AMR and drug-resistant infections is a cause for global concern. The advent of AI's application in this fight is a sign of hope; however, this area of research is still in its infancy. The application of AI and ML in clinical decision making causes much ethical concern. When it comes to human life, how can a model be trusted? Although this concern may not be fully understood, it is certainly being respected. In the context of AMR research, ML is being used as a tool to assist in the surveillance and diagnosis of potentially drug-resistant microbes. This often excludes these models from making decisions directly involving patients, and is more of a tool to be used by researchers that will eventually benefit patients down the pipeline. I believe that this is an effective application of ML in the field of medicine as it does not place the responsibility of human life on a ML model, but instead provides an additional tool for experts in the field. In my opinion, in its current form, AI and ML should be used as a tool by the expert, it should not replace the expert. 

\newpage
\bibliographystyle{abbrv}
\bibliography{main}


Key points we want to touch on:
\begin{enumerate}
    \item Examples of machine learning already being applied in the health sector.
    \item How are these machine learning examples being applied?
    \begin{enumerate}
        \item What architectures?
        \item What training techniques?
        \item What technologies?
        \item How are they getting their data? Is it a privacy risk?
    \end{enumerate}
    \item What are the implications of using machine learning in such an important sector?
    \begin{enumerate}
        \item Legal?
        \item Ethical?
        \item Medical?
    \end{enumerate}
    \item Opinion piece?
\end{enumerate}

\end{document}
