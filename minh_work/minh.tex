%%%% ijcai19-multiauthor.tex

\typeout{IJCAI-19 Multiple authors example}

% These are the instructions for authors for IJCAI-19.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai19.sty is NOT the same than previous years'
\usepackage{../ijcai19}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage[hyphens]{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym} 

\bibliographystyle{IEEEtran}


% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Application of Artificial Intelligent in Healthcare}

\author{
Ethan Garnier$^1$\footnote{Contact Author}\and
Matthew Tidd$^2$\And
Minh Nguyen$^{2}$
\affiliations
$^1$Electrical and Computer Engineering Department, UNB\\
$^2$Mechanical Engineering Department, UNB
\emails
\{ethan.garnier78, matthew.tidd, mnguyen6\}@unb.ca
}

\begin{document}

\maketitle

\begin{abstract}
This short example shows a contrived example on how to format the authors' information for {\it IJCAI--19 Proceedings} using \LaTeX{}.
\end{abstract}

\section{Introduction}

This short example shows a contrived example on how to format the authors' information for {\it IJCAI--19 Proceedings}.
\section{History of AI in Healthcare}
\subsection{Recent Developments in Healthcare AI}
Ever since the age of big data, there has been a surge in AI developments. 
This acceleration originates from several factors, including the wealth of data collected by big tech, the decreased cost of computational power, developments of more efficient machine learning techniques, and the availability of open-source machine learning packages
The healthcare and medical fields are no exclusion from this wave of AI developments. 
In fact, AI and ML application is an active field of research, receiving attention from researchers, medical stakeholders, and policy makers.
The immersion of the technology in the medical field is evident in the growth of FDA-approved AI/ML-enabled medical devices in \autoref{fig:FDA} \cite{FDA_artificial_nodate}

\begin{figure}[htbp]
    \centering{\includegraphics[scale=0.6]{../Resources/Growth in ML enabled devices.png}}
    \caption{Number of FDA-approved AI/ML-enabled medical devices since 2010} 
    \label{fig:FDA}
\end{figure}

\subsubsection{Radiology}
In radiology, machine learning is a powerful tool that can help physisicians with CT scan and MRI scan to diagnose diseases and extract latent insights from the scans. Some example work include
\begin{itemize}
    \item Classification of triple negative breast canser using ultrasound images \cite{wu_machine_2019}
    \item Detection of pulmonary lung nodules from CT scans by convolutional neural network \cite{van_ginneken_off--shelf_2015}
    \item Pneumonia detection from chest X-rays using modern deep learning \cite{rajpurkar_chexnet_2017}
    \item Detection of breast mass from mammography scans using convolutional neural networks \cite{arevalo_convolutional_2015}
\end{itemize} 



\subsubsection{Dermatology}
In dermatology diagnosis, visual inspection remains the prominent method for determining the severity of a skin abnormalities or lesions. 
Machine learning emerges as an effective automation method as they learn the latent features that differentiate between benign and malignant lesions in skin melanoma. 
As early as 1994, the research in \cite{ercal_neural_1994} applied neural network to automate the classification of malignant melanoma from melanoma-like benign tumors.
The model was given the discriminant characteristics such as tumor shape and relative color, manually extracted from digital images of skin cancer.
In \cite{esteva_dermatologist-level_2017}, a convolutional neural network was trained on 100,000 clinical images of skin cancer and achieved an accuracy similar to that of a dermatologist.
Once these models have been trained extensively on computationally efficient hardware, they can be packaged and deployed on mobile devices to make inferences on skin lesions. 
This can further increase the accessibility of machine learning functionalities to the wider population.



\subsubsection{Hematology}
In the case of hematological diseases, early prediction can help prevent progression and complication of blood disorders such as leukemia and lymphoma. 
Traditionally, practitioners diagnose hematological conditions by cytomorphologic phenotypic assessment of peripheral blood (PB) and bone marrow (BM) samples.
Newer techniques for disease diagnosis includes flow cytometry and molecular genetic analyses. 
However, diagnostic ambiguity often occurs in such manual process depending on the operator experience and capabilities. 
The reproducibility of clinical results suffer from inter- and intravariations amongst skilled hematologists and pathologists \cite{walter_artificial_2023,wu_hematologist-level_2020}.
Therefore, there needs to be an automated process for reduced reliance on expert knowledge and increased consistency in data interpretation.
Given its predictive power, machine learning implementation in disease diagnosis from blood samples is an active research topic.

In 2014, early developments of automated ML systems for cytomorphologic assessment had limited capabilities, performing tasks such as blood cell counting or classificiation of lymphoid cell types \cite{alomari_automatic_2014,alferez_automatic_2014,alferez_automatic_2015}.
In \cite{guncar_application_2018}, two ML models were developed to predict hematologic disease.
One of them was trained on all available blood test parameters and the other trained on a reduced set of parameters usually obtained from patient admittance.
When this input is paired with the knowledge of the five most likely diseases, the models achieve predictive performance on par with haematology specialists.
In a research by \textit{Wu et al.} \cite{wu_hematologist-level_2020}, the researchers developed a BMSNet with the YOLO-v3 CNN architecture to assist in BM smear interpretation.
The model performance was reported as comparable to that of expert hematologists and pathologists in various tests, except for the classification of myelodysplastic cases.
\textit{Matek et al.} \cite{matek_highly_2021} automated cytomorphologic examination of BM smears by training two CNN-based classifiers. 
The first model has the ResNeXt-50 architecture, previously used in \cite{matek_human-level_2019} for recognition of acute myeloid leukemia blast cells from PB smears due to its low number of hyperparameters.
The second model was a sequential CNN models with a simpler architecture for baseline performance comparison.
The research in \cite{cheuque_efficient_2022} employed a two-stage CNN architecture to classifies four types of white blood cells (leukocytes).
The first layer of CNN leveraged a Faster R-CNN network to delineate the regions of interest and differentiate mononuclear cells from polymorphonuclear cells. 
The seconds layer consists of two parallels CNN with the MobileNet architectures and transfer learning to further categorize the subclasses of leukocytes. 
The lightweight architecture and parallelization in the second layer allows for faster inferencing time.

Flow cytometry or multiparameter flow cytometry (MFC) is a modern techniques for routine blood analysis and an enabling factor for AI integration in hematology.
Modern MPC can analyze thousands of cells a second to generate a large dataset of high dimensional data \cite{walter_artificial_2023}. 
Although this appears challenging for human interpretation and emphasizes the reliance on expert knowledge, a machine learning algorithm can be trained to interpret the latent representation and correlation in the flow cytometry data.
The researchers in \cite{zhao_hematologist-level_2020}, leveraged machine learning by first converting MPC data into multicolor 2D images using a self-organizing map before feeding this data representation through a CNN architecture for classification.
The developed model was capable of categorizing healthy cells from diseased ones, as well as the seven subclasses of mature B-cell neoplasm.

\subsubsection{Ophthamology}
In the field of ophthamology, a fundoscopy is a non invasive procedure for inestigating the patient's fundus, or the back of their eyes, to diagnose vision conditions and risk factors leading to vision loss.
These detected factors can be used to predict the onset of diseases such as diabetic retinography, glaucoma, retina neoplasms, and macular degeneration \cite{kumar_artificial_2023}

\textbf{Diabetic retinography (DR)} is a condition where high blood sugar level causes damaged vessel in the retina. 
This condition is one of the common causes of vision loss and impairment amongst American living with diabetes and working age adults \cite{commissioner_fda_2020,abramoff_pivotal_2018}.
In 2018, the FDA approved of IDx-DR, the first AI-enabled system for detecting DR.
The research in \cite{abramoff_improved_2016} and \cite{abramoff_pivotal_2018} leveraged a multilayer CNN to train independent detectors for the anatomy and the characteristics of DR, including microaneurysms, hemorhages, and lipoprotein exudates.
The results of these detectors are combined to return the levels of the diseases. 
The study in \cite{sayres_using_2019} implemented an Inception-v4 CNN architecture, to detect the severity grade of DR and provide a heatmap of regions of interest.

Researchers have also integrated AI into the early diagnosis of \textbf{age-related macular degeneration (AMD)}, a chronic and irreversible condition and one of the most common cause of central vision loss. 
One characteristics that signals the onset of AMD is the appearance of hard or soft drusen on optical coherence tomography (OCT) images or color fundoscopy images.
ML can automate the drusen detection to diagnosie early signs of AMD, such as in \textit{Burlina et. al} \cite{burlina_automated_2017} where they employed Deep CNN on color fundus images. The network employs transfer learning on the AlexNet structure, which includes dropout lauers, ReLU activation, and normalization. The weights was trained using stochastic gradient descent and Nesterov momentum, and a learning rate of 0.001 for 50 epochs. This model was compared to a pretrained Overfeat DCNN (New York University) with a linear SVM for classification. The results showed comparable performance to expert human graders, with accuracy ranging from 88.4\% and 91.6\% and an ROC-AUC score betwen 0.94 and 0.96.
In the research done by \textit{Schlegel et al.} \cite{schlegl_fully_2018}, the authors adopted an autoencoder architecture and CNN for learning a simplified representation of the raw images (\autoref{fig:Schlegl_OCT_autoencoder} shows the architecture of this network). The encoder portion of this networks generates an optimized abstract representation of the data embedding, which is then used to re-generate a corresponding image with class labels.
\begin{figure*}[htbp]
    \centering{\includegraphics[scale=1.0]{../Resources/Schlegl_OCT_autoencoder.jpg}}
    \caption{The proposed network with an autoencoder architecture using CNN in the encoder portion to form a simplified representation of the input features} 
    \label{fig:Schlegl_OCT_autoencoder}
\end{figure*}

\textbf{Glaucoma} is another medical condition resulting in damaged optic nerve. The condition happends when there is a blockage preventing the drainage of the aqueous humor fluid and leading to pressure build-up in the eye.
In \textit{Shibata et al.} \cite{shibata_development_2018}, the authors developed a deep residual network (ResNet) for glaucoma detection from 2D fundus photography. The network is based on the CNN architecture with residual connections to prevent the gradient vanishing and gradient divergence problem, thus allowing for more effective training of deeper networks.
In a recent study by \textit{Thompson et al.} \cite{thompson_assessment_2020}, the authors implemented a deep learning solution for glaucoma detection using B-scan from OCT images. This reseach employed a residual deep convolutional neural network (ResNet34) and transfer learning to leverage the previously trainined feature extraction layers on the ImageNet dataset.


\subsubsection{Oncology}
The integration of AI and ML systems in cancer treatment is an active branch of research.
Some potential use cases of AI in this field of research are radiotherapy dosage optimization and image segmentation for tissue abnormality detection. AI algorithms have shown promising improvements compared to manual planning in these fields \cite{thompson_artificial_2018}.
In rafiation treament, the prescribed dose is determined by specialist prior to initial treatment. However, the variations in tumour biology poses challenges to this process as the dosage can significantly vary. Further complication may arise depending on the location of the tumour and surrounding organs, thus preventing the desired doseage delivery \cite{huynh_artificial_2020}. In this sense, AI methods can personalize the treatment plan and the optimal prescription achievable depending on the contour of the tumour and organs.
In \textit{Nguyen et al.} \cite{}, the authors leverage the modified U-net CNN network (\autoref{fig:U-Net_architecture_cancer_dose}) to achieve contour-to-dose mapping. Different 

\begin{figure*}[htbp]
    \centering{\includegraphics[scale=0.3]{../Resources/U-Net CNN Architecture.png}}
    \caption{Modified U-Net architecture for personalized prostate cancer dosage prescription based on patient anatomy}
    \label{fig:U-Net_architecture_cancer_dose}
\end{figure*}



\section{Challenges}
\subsection{Trust}
\subsection{Accountability}
\subsection{Data privacy and protection}
AI technologies depend on a vast amount of patient data and record to make accurate predictions when subjected to unseen data.
However, in the event of a database violation or data breach, confidential patient information can be exploited for malicious intentions (identity theft, social stigma, discrimination,...).
This can put a mental burden on the patient suceptible to the violation and other relevant stakeholders.
Therefore, adequate law and guidelines are crucial to regulate the application of AI in medical and prevent misuse of data


The data gathering and handling of health data in the US is controversial, raising legal and ethical privacy questions \cite{price_privacy_2019}.
Although the data can originate from various sources, such as healthcare providers, insurance claim, and wearable devices, US privacy law operates in different extents depending on the data source.
This law also depends on the custodian of the data. Under the Health Insurance Portability and Accountability Act (HIPAA), the federal Privacy Rule only governs data handling between the conventional entities, such as healthcare providers, health insurance provides, patients, and intermediaries. 
However, \cite{price_privacy_2019} pointed out existing gap in HIPAA regulation.
Although, HIPAA protect patient privacy from health data breach via a deindentifying process, patient data can be reidentified through data triangulation from other datasets.


Furthermore, a more fundamental problem is the amount of health related data not regulated under HIPAA \cite{price_privacy_2019}. 
Originally enacted to regulate data privacy in health records and between covered entities, HIPAA does not account for health data generate outside the confinement of these covered entities. 
In the big data world, tech companies are displacing covered entities in the collection of health information and personal data from online searches, application logs, and smart wearable devices.

\section{Conclusion}

\section{Template notes}

\subsection{Author names}

Each author name must be followed by:
\begin{itemize}
    \item A newline {\tt \textbackslash{}\textbackslash{}} command for the last author.
    \item An {\tt \textbackslash{}And} command for the second to last author.
    \item An {\tt \textbackslash{}and} command for the other authors.
\end{itemize}

\subsection{Affiliations}

After all authors, start the affiliations section by using the {\tt \textbackslash{}affiliations} command.
Each affiliation must be terminated by a newline {\tt \textbackslash{}\textbackslash{}} command. Make sure that you include the newline on the last affiliation too.

\subsection{Mapping authors to affiliations}

If some scenarios, the affiliation of each author is clear without any further indication (\emph{e.g.}, all authors share the same affiliation, all authors have a single and different affiliation). In these situations you don't need to do anything special.

In more complex scenarios you will have to clearly indicate the affiliation(s) for each author. This is done by using numeric math superscripts {\tt \$\{\^{}$i,j, \ldots$\}\$}. You must use numbers, not symbols, because those are reserved for footnotes in this section (should you need them). Check the authors definition in this example for reference.

\subsection{Emails}

This section is optional, and can be omitted entirely if you prefer. If you want to include e-mails, you should either include all authors' e-mails or just the contact author(s)' ones.

Start the e-mails section with the {\tt \textbackslash{}emails} command. After that, write all emails you want to include separated by a comma and a space, following the same order used for the authors (\emph{i.e.}, the first e-mail should correspond to the first author, the second e-mail to the second author and so on).

You may ``contract" consecutive e-mails on the same domain as shown in this example (write the users' part within curly brackets, followed by the domain name). Only e-mails of the exact same domain may be contracted. For instance, contracting ``person@example.com" and ``other@test.example.com" is not allowed because the domains are different.


% Bibliography/Reference Stuff
\bibliography{minh}
\end{document}