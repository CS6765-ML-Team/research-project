@article{price_privacy_2019,
	title = {Privacy in the age of medical big data},
	volume = {25},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0272-7},
	doi = {10.1038/s41591-018-0272-7},
	language = {en},
	number = {1},
	urldate = {2024-10-04},
	journal = {Nature Medicine},
	author = {Price, W. Nicholson and Cohen, I. Glenn},
	month = jan,
	year = {2019},
	pages = {37--43},
	file = {PDF:C\:\\Users\\caomi\\Zotero\\storage\\RH9N9GTP\\Price and Cohen - 2019 - Privacy in the age of medical big data.pdf:application/pdf},
}


@article{wu_machine_2019,
	title = {Machine learning for diagnostic ultrasound of triple-negative breast cancer},
	volume = {173},
	issn = {1573-7217},
	url = {https://doi.org/10.1007/s10549-018-4984-7},
	doi = {10.1007/s10549-018-4984-7},
	abstract = {Early diagnosis of triple-negative (TN) breast cancer is important due to its aggressive biological characteristics, poor clinical outcomes, and limited options for therapy. The goal of this study is to evaluate the potential of machine learning with quantitative ultrasound image features for the diagnosis of TN breast cancer.},
	language = {en},
	number = {2},
	urldate = {2024-10-16},
	journal = {Breast Cancer Research and Treatment},
	author = {Wu, Tong and Sultan, Laith R. and Tian, Jiawei and Cary, Theodore W. and Sehgal, Chandra M.},
	month = jan,
	year = {2019},
	keywords = {Breast cancer, Computer-aided diagnosis, Machine learning, Quantitative breast ultrasound, Triple negative breast cancer},
	pages = {365--373},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\3IFKX8IS\\Wu et al. - 2019 - Machine learning for diagnostic ultrasound of triple-negative breast cancer.pdf:application/pdf},
}

@inproceedings{van_ginneken_off--shelf_2015,
	title = {Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans},
	url = {https://ieeexplore.ieee.org/abstract/document/7163869},
	doi = {10.1109/ISBI.2015.7163869},
	abstract = {Convolutional neural networks (CNNs) have emerged as the most powerful technique for a range of different tasks in computer vision. Recent work suggested that CNN features are generic and can be used for classification tasks outside the exact domain for which the networks were trained. In this work we use the features from one such network, OverFeat, trained for object detection in natural images, for nodule detection in computed tomography scans. We use 865 scans from the publicly available LIDC data set, read by four thoracic radiologists. Nodule candidates are generated by a state-of-the-art nodule detection system. We extract 2D sagittal, coronal and axial patches for each nodule candidate and extract 4096 features from the penultimate layer of OverFeat and classify these with linear support vector machines. We show for various configurations that the off-the-shelf CNN features perform surprisingly well, but not as good as the dedicated detection system. When both approaches are combined, significantly better results are obtained than either approach alone. We conclude that CNN features have great potential to be used for detection tasks in volumetric medical data.},
	urldate = {2024-10-16},
	booktitle = {2015 {IEEE} 12th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {van Ginneken, Bram and Setio, Arnaud A. A. and Jacobs, Colin and Ciompi, Francesco},
	month = apr,
	year = {2015},
	note = {ISSN: 1945-8452},
	keywords = {Biomedical imaging, Cancer, computed tomography, Computed tomography, convolutional neural networks, Design automation, Feature extraction, Lesions, Lungs, Nodule detection},
	pages = {286--289},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\caomi\\Zotero\\storage\\62EPRISW\\7163869.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\LUKV5NDA\\van Ginneken et al. - 2015 - Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomog.pdf:application/pdf},
}

@misc{rajpurkar_chexnet_2017,
	title = {{CheXNet}: {Radiologist}-{Level} {Pneumonia} {Detection} on {Chest} {X}-{Rays} with {Deep} {Learning}},
	shorttitle = {{CheXNet}},
	url = {http://arxiv.org/abs/1711.05225},
	doi = {10.48550/arXiv.1711.05225},
	abstract = {We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.},
	urldate = {2024-10-16},
	publisher = {arXiv},
	author = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and Lungren, Matthew P. and Ng, Andrew Y.},
	month = dec,
	year = {2017},
	note = {arXiv:1711.05225 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\caomi\\Zotero\\storage\\K6NZCHJ4\\Rajpurkar et al. - 2017 - CheXNet Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\9LUZTCYX\\1711.html:text/html},
}

@inproceedings{arevalo_convolutional_2015,
	title = {Convolutional neural networks for mammography mass lesion classification},
	url = {https://ieeexplore.ieee.org/document/7318482/?arnumber=7318482},
	doi = {10.1109/EMBC.2015.7318482},
	abstract = {Feature extraction is a fundamental step when mammography image analysis is addressed using learning based approaches. Traditionally, problem dependent handcrafted features are used to represent the content of images. An alternative approach successfully applied in other domains is the use of neural networks to automatically discover good features. This work presents an evaluation of convolutional neural networks to learn features for mammography mass lesions before feeding them to a classification stage. Experimental results showed that this approach is a suitable strategy outperforming the state-of-the-art representation from 79.9\% to 86\% in terms of area under the ROC curve.},
	urldate = {2024-10-16},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Arevalo, John and González, Fabio A. and Ramos-Pollán, Raúl and Oliveira, Jose L. and Guevara Lopez, Miguel Angel},
	month = aug,
	year = {2015},
	note = {ISSN: 1558-4615},
	keywords = {Breast cancer, Feature extraction, Lesions, Machine learning, Shape, Training},
	pages = {797--800},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\caomi\\Zotero\\storage\\YLJ8BJRU\\7318482.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\TU5EQTWX\\Arevalo et al. - 2015 - Convolutional neural networks for mammography mass lesion classification.pdf:application/pdf},
}

@article{esteva_dermatologist-level_2017,
	title = {Dermatologist-level classification of skin cancer with deep neural networks},
	volume = {542},
	copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature21056},
	doi = {10.1038/nature21056},
	abstract = {An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists.},
	language = {en},
	number = {7639},
	urldate = {2024-10-16},
	journal = {Nature},
	author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
	month = feb,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Machine learning, Skin cancer},
	pages = {115--118},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\8P5AMYCV\\Esteva et al. - 2017 - Dermatologist-level classification of skin cancer with deep neural networks.pdf:application/pdf},
}

@article{guncar_application_2018,
	title = {An application of machine learning to haematological diagnosis},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-18564-8},
	doi = {10.1038/s41598-017-18564-8},
	abstract = {Quick and accurate medical diagnoses are crucial for the successful treatment of diseases. Using machine learning algorithms and based on laboratory blood test results, we have built two models to predict a haematologic disease. One predictive model used all the available blood test parameters and the other used only a reduced set that is usually measured upon patient admittance. Both models produced good results, obtaining prediction accuracies of 0.88 and 0.86 when considering the list of five most likely diseases and 0.59 and 0.57 when considering only the most likely disease. The models did not differ significantly, which indicates that a reduced set of parameters can represent a relevant “fingerprint” of a disease. This knowledge expands the model’s utility for use by general practitioners and indicates that blood test results contain more information than physicians generally recognize. A clinical test showed that the accuracy of our predictive models was on par with that of haematology specialists. Our study is the first to show that a machine learning predictive model based on blood tests alone can be successfully applied to predict haematologic diseases. This result and could open up unprecedented possibilities for medical diagnosis.},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Scientific Reports},
	author = {Gunčar, Gregor and Kukar, Matjaž and Notar, Mateja and Brvar, Miran and Černelč, Peter and Notar, Manca and Notar, Marko},
	month = jan,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Software},
	pages = {411},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\CRN3LBGB\\Gunčar et al. - 2018 - An application of machine learning to haematological diagnosis.pdf:application/pdf},
}

@article{walter_artificial_2023,
	title = {Artificial intelligence in hematological diagnostics: {Game} changer or gadget?},
	volume = {58},
	issn = {0268960X},
	shorttitle = {Artificial intelligence in hematological diagnostics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0268960X22000935},
	doi = {10.1016/j.blre.2022.101019},
	abstract = {The future of clinical diagnosis and treatment of hematologic diseases will inevitably involve the integration of artificial intelligence (AI)-based systems into routine practice to support the hematologists' decision making. Several studies have shown that AI-based models can already be used to automatically differentiate cells, reliably detect malignant cell populations, support chromosome banding analysis, and interpret clinical variants, contributing to early disease detection and prognosis. However, even the best tool can become useless if it is misapplied or the results are misinterpreted. Therefore, in order to comprehensively judge and correctly apply newly developed AI-based systems, the hematologist must have a basic understanding of the general concepts of machine learning. In this review, we provide the hematologist with a comprehensive overview of various machine learning techniques, their current implementations and approaches in different diagnostic subfields (e.g., cytogenetics, molecular genetics), and the limitations and unresolved challenges of the systems.},
	language = {en},
	urldate = {2024-10-17},
	journal = {Blood Reviews},
	author = {Walter, Wencke and Pohlkamp, Christian and Meggendorfer, Manja and Nadarajah, Niroshan and Kern, Wolfgang and Haferlach, Claudia and Haferlach, Torsten},
	month = mar,
	year = {2023},
	pages = {101019},
	file = {PDF:C\:\\Users\\caomi\\Zotero\\storage\\KW3IRFDH\\Walter et al. - 2023 - Artificial intelligence in hematological diagnostics Game changer or gadget.pdf:application/pdf},
}

@misc{FDA_artificial_nodate,
	title = {Artificial {Intelligence} and {Machine} {Learning} ({AI}/{ML})-{Enabled} {Medical} {Devices} {\textbar} {FDA}},
	url = {https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices},
	author = {FDA},
	year = {2024},
	urldate = {2024-10-17},
	file = {Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices | FDA:C\:\\Users\\caomi\\Zotero\\storage\\7472SENF\\artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices.html:text/html},
}

@article{ercal_neural_1994,
	title = {Neural network diagnosis of malignant melanoma from color images},
	volume = {41},
	issn = {0018-9294},
	doi = {10.1109/10.312091},
	abstract = {Malignant melanoma is the deadliest form of all skin cancers. Approximately 32,000 new cases of malignant melanoma were diagnosed in 1991 in the United States, with approximately 80\% of patients expected to survive five years [1]. Fortunately, if detected early, even malignant melanoma may be treated successfully. Thus, in recent years, there has been rising interest in the automated detection and diagnosis of skin cancer, particularly malignant melanoma [2]. In this paper, we present a novel neural network approach for the automated separation of melanoma from three benign categories of tumors which exhibit melanoma-like characteristics. Our approach uses discriminant features, based on tumor shape and relative tumor color, that are supplied to an artificial neural network for classification of tumor images as malignant or benign. With this approach, for reasonably balanced training/testing sets, we are able to obtain above 80\% correct classification of the malignant and benign tumors on real skin tumor images.},
	language = {eng},
	number = {9},
	journal = {IEEE transactions on bio-medical engineering},
	author = {Ercal, F. and Chawla, A. and Stoecker, W. V. and Lee, H. C. and Moss, R. H.},
	month = sep,
	year = {1994},
	pmid = {7959811},
	keywords = {Adolescent, Adult, Child, Color, Diagnosis, Computer-Assisted, Humans, Image Interpretation, Computer-Assisted, Melanoma, Models, Biological, Neural Networks, Computer, Skin Neoplasms},
	pages = {837--845},
}

@article{kumar_artificial_2023,
	title = {Artificial {Intelligence} in {Healthcare}: {Review}, {Ethics}, {Trust} {Challenges} \& {Future} {Research} {Directions}},
	volume = {120},
	issn = {0952-1976},
	shorttitle = {Artificial {Intelligence} in {Healthcare}},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197623000787},
	doi = {10.1016/j.engappai.2023.105894},
	abstract = {The use of artificial intelligence (AI) in medicine is beginning to alter current procedures in prevention, diagnosis, treatment, amelioration, cure of disease and other physical and mental impairments. In addition to raising concerns about public trust and ethics, advancements in this new emerging technology have also led to a lot of debate around its integration into healthcare. The objective of this work is to introduce researchers to AI and its medical applications, along with their potential pitfalls, in a comprehensive manner. This paper provides a review of current studies that have investigated how to apply AI methodologies to create a smart predictive maintenance model for the industries of the future. We begin with a brief introduction to AI and a decade’s worth of its advancements across a variety of industries, including smart grids, train transportation, etc., and most recently, healthcare. In this paper, we explore the various applications of AI across various medical specialties, including radiology, dermatology, haematology, ophthalmology, etc. along with the comparative study by employing several key criteria. Finally, it highlights the challenges for large-scale integration of AI in medical systems along with a summary of the ethical, legal, trust, and future implications of AI in healthcare.},
	urldate = {2024-09-27},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Kumar, Pranjal and Chauhan, Siddhartha and Awasthi, Lalit Kumar},
	month = apr,
	year = {2023},
	keywords = {Artificial intelligence, Machine learning, Deep learning, Healthcare, Ethics, Trust},
	pages = {105894},
	annote = {This paper provides a holistic review of AI applications in healthcare, focusing more on the social aspects
},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\UQRDNR6G\\Kumar et al. - 2023 - Artificial Intelligence in Healthcare Review, Ethics, Trust Challenges & Future Research Directions.pdf:application/pdf},
}


@misc{commissioner_fda_2020,
	title = {{FDA} permits marketing of artificial intelligence-based device to detect certain diabetes-related eye problems},
	url = {https://www.fda.gov/news-events/press-announcements/fda-permits-marketing-artificial-intelligence-based-device-detect-certain-diabetes-related-eye},
	abstract = {FDA permits marketing of first medical device to use artificial intelligence to detect greater than a mild level of diabetic retinopathy in the eye of adults who have diabetes.},
	language = {en},
	urldate = {2024-10-21},
	journal = {FDA},
	author = {Commissioner, Office of the},
	month = mar,
	year = {2020},
	note = {Publisher: FDA},
	file = {Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\FGUA8M7G\\fda-permits-marketing-artificial-intelligence-based-device-detect-certain-diabetes-related-eye.html:text/html},
}

@article{abramoff_pivotal_2018,
	title = {Pivotal trial of an autonomous {AI}-based diagnostic system for detection of diabetic retinopathy in primary care offices},
	volume = {1},
	copyright = {2018 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-018-0040-6},
	doi = {10.1038/s41746-018-0040-6},
	abstract = {Artificial Intelligence (AI) has long promised to increase healthcare affordability, quality and accessibility but FDA, until recently, had never authorized an autonomous AI diagnostic system. This pivotal trial of an AI system to detect diabetic retinopathy (DR) in people with diabetes enrolled 900 subjects, with no history of DR at primary care clinics, by comparing to Wisconsin Fundus Photograph Reading Center (FPRC) widefield stereoscopic photography and macular Optical Coherence Tomography (OCT), by FPRC certified photographers, and FPRC grading of Early Treatment Diabetic Retinopathy Study Severity Scale (ETDRS) and Diabetic Macular Edema (DME). More than mild DR (mtmDR) was defined as ETDRS level 35 or higher, and/or DME, in at least one eye. AI system operators underwent a standardized training protocol before study start. Median age was 59 years (range, 22–84 years); among participants, 47.5\% of participants were male; 16.1\% were Hispanic, 83.3\% not Hispanic; 28.6\% African American and 63.4\% were not; 198 (23.8\%) had mtmDR. The AI system exceeded all pre-specified superiority endpoints at sensitivity of 87.2\% (95\% CI, 81.8–91.2\%) ({\textgreater}85\%), specificity of 90.7\% (95\% CI, 88.3–92.7\%) ({\textgreater}82.5\%), and imageability rate of 96.1\% (95\% CI, 94.6–97.3\%), demonstrating AI’s ability to bring specialty-level diagnostics to primary care settings. Based on these results, FDA authorized the system for use by health care providers to detect more than mild DR and diabetic macular edema, making it, the first FDA authorized autonomous AI diagnostic system in any field of medicine, with the potential to help prevent vision loss in thousands of people with diabetes annually. ClinicalTrials.gov NCT02963441},
	language = {en},
	number = {1},
	urldate = {2024-10-21},
	journal = {npj Digital Medicine},
	author = {Abràmoff, Michael D. and Lavin, Philip T. and Birch, Michele and Shah, Nilay and Folk, James C.},
	month = aug,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Eye manifestations},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\8E4LQCE8\\Abràmoff et al. - 2018 - Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in p.pdf:application/pdf},
}

@article{abramoff_improved_2016,
	title = {Improved {Automated} {Detection} of {Diabetic} {Retinopathy} on a {Publicly} {Available} {Dataset} {Through} {Integration} of {Deep} {Learning}},
	volume = {57},
	issn = {1552-5783},
	url = {https://doi.org/10.1167/iovs.16-19964},
	doi = {10.1167/iovs.16-19964},
	abstract = {To compare performance of a deep-learning enhanced algorithm for automated detection of diabetic retinopathy (DR), to the previously published performance of that algorithm, the Iowa Detection Program (IDP)–without deep learning components–on the same publicly available set of fundus images and previously reported consensus reference standard set, by three US Board certified retinal specialists.    We used the previously reported consensus reference standard of referable DR (rDR), defined as International Clinical Classification of Diabetic Retinopathy moderate, severe nonproliferative (NPDR), proliferative DR, and/or macular edema (ME). Neither Messidor-2 images, nor the three retinal specialists setting the Messidor-2 reference standard were used for training IDx-DR version X2.1. Sensitivity, specificity, negative predictive value, area under the curve (AUC), and their confidence intervals (CIs) were calculated.    Sensitivity was 96.8\% (95\% CI: 93.3\%–98.8\%), specificity was 87.0\% (95\% CI: 84.2\%–89.4\%), with 6/874 false negatives, resulting in a negative predictive value of 99.0\% (95\% CI: 97.8\%–99.6\%). No cases of severe NPDR, PDR, or ME were missed. The AUC was 0.980 (95\% CI: 0.968–0.992). Sensitivity was not statistically different from published IDP sensitivity, which had a CI of 94.4\% to 99.3\%, but specificity was significantly better than the published IDP specificity CI of 55.7\% to 63.0\%.    A deep-learning enhanced algorithm for the automated detection of DR, achieves significantly better performance than a previously reported, otherwise essentially identical, algorithm that does not employ deep learning. Deep learning enhanced algorithms have the potential to improve the efficiency of DR screening, and thereby to prevent visual loss and blindness from this devastating disease.},
	number = {13},
	urldate = {2024-10-21},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Abràmoff, Michael David and Lou, Yiyue and Erginay, Ali and Clarida, Warren and Amelon, Ryan and Folk, James C. and Niemeijer, Meindert},
	month = oct,
	year = {2016},
	pages = {5200--5206},
	file = {Full Text:C\:\\Users\\caomi\\Zotero\\storage\\E37FMBWZ\\Abràmoff et al. - 2016 - Improved Automated Detection of Diabetic Retinopathy on a Publicly Available Dataset Through Integra.pdf:application/pdf;Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\8SM6TRS2\\article.html:text/html},
}

@article{sayres_using_2019,
	title = {Using a {Deep} {Learning} {Algorithm} and {Integrated} {Gradients} {Explanation} to {Assist} {Grading} for {Diabetic} {Retinopathy}},
	volume = {126},
	issn = {01616420},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0161642018315756},
	doi = {10.1016/j.ophtha.2018.11.016},
	abstract = {Purpose: To understand the impact of deep learning diabetic retinopathy (DR) algorithms on physician readers in computer-assisted settings. Design: Evaluation of diagnostic technology. Participants: One thousand seven hundred ninety-six retinal fundus images from 1612 diabetic patients.
Methods: Ten ophthalmologists (5 general ophthalmologists, 4 retina specialists, 1 retina fellow) read images for DR severity based on the International Clinical Diabetic Retinopathy disease severity scale in each of 3 conditions: unassisted, grades only, or grades plus heatmap. Grades-only assistance comprised a histogram of DR predictions (grades) from a trained deep-learning model. For grades plus heatmap, we additionally showed explanatory heatmaps. Main Outcome Measures: For each experiment arm, we computed sensitivity and speciﬁcity of each reader and the algorithm for different levels of DR severity against an adjudicated reference standard. We also measured accuracy (exact 5-class level agreement and Cohen’s quadratically weighted k), reader-reported conﬁdence (5-point Likert scale), and grading time.
Results: Readers graded more accurately with model assistance than without for the grades-only condition (P {\textless} 0.001). Grades plus heatmaps improved accuracy for patients with DR (P {\textless} 0.001), but reduced accuracy for patients without DR (P ¼ 0.006). Both forms of assistance increased readers’ sensitivity moderate-or-worse DR: unassisted: mean, 79.4\% [95\% conﬁdence interval (CI), 72.3\%e86.5\%]; grades only: mean, 87.5\% [95\% CI, 85.1\%e89.9\%]; grades plus heatmap: mean, 88.7\% [95\% CI, 84.9\%e92.5\%] without a corresponding drop in speciﬁcity (unassisted: mean, 96.6\% [95\% CI, 95.9\%e97.4\%]; grades only: mean, 96.1\% [95\% CI, 95.5\%e 96.7\%]; grades plus heatmap: mean, 95.5\% [95\% CI, 94.8\%e96.1\%]). Algorithmic assistance increased the accuracy of retina specialists above that of the unassisted reader or model alone; and increased grading conﬁdence and grading time across all readers. For most cases, grades plus heatmap was only as effective as grades only. Over the course of the experiment, grading time decreased across all conditions, although most sharply for grades plus heatmap.
Conclusions: Deep learning algorithms can improve the accuracy of, and conﬁdence in, DR diagnosis in an assisted read setting. They also may increase grading time, although these effects may be ameliorated with experience. Ophthalmology 2019;126:552-564 ª 2018 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
	language = {en},
	number = {4},
	urldate = {2024-10-21},
	journal = {Ophthalmology},
	author = {Sayres, Rory and Taly, Ankur and Rahimy, Ehsan and Blumer, Katy and Coz, David and Hammel, Naama and Krause, Jonathan and Narayanaswamy, Arunachalam and Rastegar, Zahra and Wu, Derek and Xu, Shawn and Barb, Scott and Joseph, Anthony and Shumski, Michael and Smith, Jesse and Sood, Arjun B. and Corrado, Greg S. and Peng, Lily and Webster, Dale R.},
	month = apr,
	year = {2019},
	pages = {552--564},
	file = {PDF:C\:\\Users\\caomi\\Zotero\\storage\\78QYR35Z\\Sayres et al. - 2019 - Using a Deep Learning Algorithm and Integrated Gradients Explanation to Assist Grading for Diabetic.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\VFY94J54\\S0161642018315756.html:text/html},
}


@article{alomari_automatic_2014,
	title = {Automatic {Detection} and {Quantification} of {WBCs} and {RBCs} {Using} {Iterative} {Structured} {Circle} {Detection} {Algorithm}},
	volume = {2014},
	issn = {1748-6718},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2014/979302},
	doi = {10.1155/2014/979302},
	abstract = {Segmentation and counting of blood cells are considered as an important step that helps to extract features to diagnose some specific diseases like malaria or leukemia. The manual counting of white blood cells (WBCs) and red blood cells (RBCs) in microscopic images is an extremely tedious, time consuming, and inaccurate process. Automatic analysis will allow hematologist experts to perform faster and more accurately. The proposed method uses an iterative structured circle detection algorithm for the segmentation and counting of WBCs and RBCs. The separation of WBCs from RBCs was achieved by thresholding, and specific preprocessing steps were developed for each cell type. Counting was performed for each image using the proposed method based on modified circle detection, which automatically counted the cells. Several modifications were made to the basic (RCD) algorithm to solve the initialization problem, detecting irregular circles (cells), selecting the optimal circle from the candidate circles, determining the number of iterations in a fully dynamic way to enhance algorithm detection, and running time. The validation method used to determine segmentation accuracy was a quantitative analysis that included Precision, Recall, and F-measurement tests. The average accuracy of the proposed method was 95.3\% for RBCs and 98.4\% for WBCs.},
	language = {en},
	number = {1},
	urldate = {2024-10-21},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Alomari, Yazan M. and Sheikh Abdullah, Siti Norul Huda and Zaharatul Azma, Raja and Omar, Khairuddin},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2014/979302},
	pages = {979302},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\H6JB6QHU\\Alomari et al. - 2014 - Automatic Detection and Quantification of WBCs and RBCs Using Iterative Structured Circle Detection.pdf:application/pdf;Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\I9DCSK69\\979302.html:text/html},
}

@article{alferez_automatic_2014,
	title = {Automatic classification of atypical lymphoid {B} cells using digital blood image processing},
	volume = {36},
	copyright = {© 2013 John Wiley \& Sons Ltd},
	issn = {1751-553X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijlh.12175},
	doi = {10.1111/ijlh.12175},
	abstract = {Introduction There are automated systems for digital peripheral blood (PB) cell analysis, but they operate most effectively in nonpathological blood samples. The objective of this work was to design a methodology to improve the automatic classification of abnormal lymphoid cells. Methods We analyzed 340 digital images of individual lymphoid cells from PB films obtained in the CellaVision DM96:150 chronic lymphocytic leukemia (CLL) cells, 100 hairy cell leukemia (HCL) cells, and 90 normal lymphocytes (N). We implemented the Watershed Transformation to segment the nucleus, the cytoplasm, and the peripheral cell region. We extracted 44 features and then the clustering Fuzzy C-Means (FCM) was applied in two steps for the lymphocyte classification. Results The images were automatically clustered in three groups, one of them with 98\% of the HCL cells. The set of the remaining cells was clustered again using FCM and texture features. The two new groups contained 83.3\% of the N cells and 71.3\% of the CLL cells, respectively. Conclusion The approach has been able to automatically classify with high precision three types of lymphoid cells. The addition of more descriptors and other classification techniques will allow extending the classification to other classes of atypical lymphoid cells.},
	language = {en},
	number = {4},
	urldate = {2024-10-21},
	journal = {International Journal of Laboratory Hematology},
	author = {Alférez, S. and Merino, A. and Mujica, L. E. and Ruiz, M. and Bigorra, L. and Rodellar, J.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ijlh.12175},
	keywords = {Atypical lymphoid cells, automatic cell classification, digital image processing, hematological cytology, morphological analysis, peripheral blood},
	pages = {472--480},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\CSU47VFP\\Alférez et al. - 2014 - Automatic classification of atypical lymphoid B cells using digital blood image processing.pdf:application/pdf;Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\C3PT3PAJ\\ijlh.html:text/html},
}

@article{alferez_automatic_2015,
	title = {Automatic recognition of atypical lymphoid cells from peripheral blood by digital image analysis},
	volume = {143},
	doi = {10.1309/AJCP78IFSTOGZZJN},
	abstract = {Objectives: The objective was the development of a method for the automatic recognition of different types of atypical lymphoid cells. Methods: In the method development, a training set (TS) of 1,500 lymphoid cell images from peripheral blood was used. To segment the images, we used clustering of color components and watershed transformation. In total, 113 features were extracted for lymphocyte recognition by linear discriminant analysis (LDA) with a 10-fold cross-validation over the TS. Then, a new validation set (VS) of 150 images was used, performing two steps: (1) tuning the LDA classifier using the TS and (2) classifying the VS in the different lymphoid cell types. Results: The segmentation algorithm was very effective in separating the cytoplasm, nucleus, and peripheral zone around the cell. From them, descriptive features were extracted and used to recognize the different lymphoid cells. The accuracy for the classification in the TS was 98.07\%. The precision, sensitivity, and specificity values were above 99.7\%, 97.5\%, and 98.6\%, respectively. The accuracy of the classification in the VS was 85.33\%. Conclusions: The method reaches a high precision in the recognition of five different types of lymphoid cells and could allow for the design of a diagnosis support tool in the future. © American Society for Clinical Pathology.},
	number = {2},
	journal = {American Journal of Clinical Pathology},
	author = {Alférez, S. and Merino, A. and Bigorra, L. and Mujica, L. and Ruiz, M. and Rodellar, J.},
	year = {2015},
	keywords = {Atypical lymphoid cells, Automatic cell classification, Digital image processing, Hematologic cytology, Morphologic analysis, Peripheral blood},
	pages = {168--176},
	file = {Full Text:C\:\\Users\\caomi\\Zotero\\storage\\378PH74J\\Alférez et al. - 2015 - Automatic recognition of atypical lymphoid cells from peripheral blood by digital image analysis.pdf:application/pdf;Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\F6HLBP46\\display.html:text/html},
}


@article{cheuque_efficient_2022,
	title = {An {Efficient} {Multi}-{Level} {Convolutional} {Neural} {Network} {Approach} for {White} {Blood} {Cells} {Classification}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2075-4418},
	url = {https://www.mdpi.com/2075-4418/12/2/248},
	doi = {10.3390/diagnostics12020248},
	abstract = {The evaluation of white blood cells is essential to assess the quality of the human immune system; however, the assessment of the blood smear depends on the pathologist’s expertise. Most machine learning tools make a one-level classification for white blood cell classification. This work presents a two-stage hybrid multi-level scheme that efficiently classifies four cell groups: lymphocytes and monocytes (mononuclear) and segmented neutrophils and eosinophils (polymorphonuclear). At the first level, a Faster R-CNN network is applied for the identification of the region of interest of white blood cells, together with the separation of mononuclear cells from polymorphonuclear cells. Once separated, two parallel convolutional neural networks with the MobileNet structure are used to recognize the subclasses in the second level. The results obtained using Monte Carlo cross-validation show that the proposed model has a performance metric of around 98.4\% (accuracy, recall, precision, and F1-score). The proposed model represents a good alternative for computer-aided diagnosis (CAD) tools for supporting the pathologist in the clinical laboratory in assessing white blood cells from blood smear images.},
	language = {en},
	number = {2},
	urldate = {2024-10-21},
	journal = {Diagnostics},
	author = {Cheuque, César and Querales, Marvin and León, Roberto and Salas, Rodrigo and Torres, Romina},
	month = feb,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, multi-level classification, multi-source datasets, white blood cells classification},
	pages = {248},
	file = {Full Text PDF:C\:\\Users\\caomi\\Zotero\\storage\\DP8VDLYP\\Cheuque et al. - 2022 - An Efficient Multi-Level Convolutional Neural Network Approach for White Blood Cells Classification.pdf:application/pdf},
}

@article{wu_hematologist-level_2020,
	title = {A {Hematologist}-{Level} {Deep} {Learning} {Algorithm} ({BMSNet}) for {Assessing} the {Morphologies} of {Single} {Nuclear} {Balls} in {Bone} {Marrow} {Smears}: {Algorithm} {Development}},
	volume = {8},
	copyright = {This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published JMIR Medical Informatics, is properly cited. The complete bibliographic information, a link to the original publication on https://medinform.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {A {Hematologist}-{Level} {Deep} {Learning} {Algorithm} ({BMSNet}) for {Assessing} the {Morphologies} of {Single} {Nuclear} {Balls} in {Bone} {Marrow} {Smears}},
	url = {https://medinform.jmir.org/2020/4/e15963},
	doi = {10.2196/15963},
	abstract = {Background: Bone marrow aspiration and biopsy remain the gold standard for the diagnosis of hematological diseases despite the development of flow cytometry (FCM) and molecular and gene analyses. However, the interpretation of the results is laborious and operator dependent. Furthermore, the obtained results exhibit inter- and intravariations among specialists. Therefore, it is important to develop a more objective and automated analysis system. Several deep learning models have been developed and applied in medical image analysis but not in the field of hematological histology, especially for bone marrow smear applications. Objective: The aim of this study was to develop a deep learning model (BMSNet) for assisting hematologists in the interpretation of bone marrow smears for faster diagnosis and disease monitoring. Methods: From January 1, 2016, to December 31, 2018, 122 bone marrow smears were photographed and divided into a development cohort (N=42), a validation cohort (N=70), and a competition cohort (N=10). The development cohort included 17,319 annotated cells from 291 high-resolution photos. In total, 20 photos were taken for each patient in the validation cohort and the competition cohort. This study included eight annotation categories: erythroid, blasts, myeloid, lymphoid, plasma cells, monocyte, megakaryocyte, and unable to identify. BMSNet is a convolutional neural network with the YOLO v3 architecture, which detects and classifies single cells in a single model. Six visiting staff members participated in a human-machine competition, and the results from the FCM were regarded as the ground truth. Results: In the development cohort, according to 6-fold cross-validation, the average precision of the bounding box prediction without consideration of the classification is 67.4\%. After removing the bounding box prediction error, the precision and recall of BMSNet were similar to those of the hematologists in most categories. In detecting more than 5\% of blasts in the validation cohort, the area under the curve (AUC) of BMSNet (0.948) was higher than the AUC of the hematologists (0.929) but lower than the AUC of the pathologists (0.985). In detecting more than 20\% of blasts, the AUCs of the hematologists (0.981) and pathologists (0.980) were similar and were higher than the AUC of BMSNet (0.942). Further analysis showed that the performance difference could be attributed to the myelodysplastic syndrome cases. In the competition cohort, the mean value of the correlations between BMSNet and FCM was 0.960, and the mean values of the correlations between the visiting staff and FCM ranged between 0.952 and 0.990. Conclusions: Our deep learning model can assist hematologists in interpreting bone marrow smears by facilitating and accelerating the detection of hematopoietic cells. However, a detailed morphological interpretation still requires trained hematologists.},
	language = {EN},
	number = {4},
	urldate = {2024-10-22},
	journal = {JMIR Medical Informatics},
	author = {Wu, Yi-Ying and Huang, Tzu-Chuan and Ye, Ren-Hua and Fang, Wen-Hui and Lai, Shiue-Wei and Chang, Ping-Ying and Liu, Wei-Nung and Kuo, Tai-Yu and Lee, Cho-Hao and Tsai, Wen-Chiuan and Lin, Chin},
	month = apr,
	year = {2020},
	note = {Company: JMIR Medical Informatics
Distributor: JMIR Medical Informatics
Institution: JMIR Medical Informatics
Label: JMIR Medical Informatics
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e15963},
	file = {Full Text:C\:\\Users\\caomi\\Zotero\\storage\\6R76QG8A\\Wu et al. - 2020 - A Hematologist-Level Deep Learning Algorithm (BMSNet) for Assessing the Morphologies of Single Nucle.pdf:application/pdf;Snapshot:C\:\\Users\\caomi\\Zotero\\storage\\9W7YUZ5X\\e15963.html:text/html},
}

@article{matek_highly_2021,
	title = {Highly accurate differentiation of bone marrow cell morphologies using deep neural networks on a large image data set},
	volume = {138},
	issn = {0006-4971, 1528-0020},
	url = {https://ashpublications.org/blood/article/138/20/1917/477932/Highly-accurate-differentiation-of-bone-marrow},
	doi = {10.1182/blood.2020010568},
	abstract = {Abstract
            Biomedical applications of deep learning algorithms rely on large expert annotated data sets. The classification of bone marrow (BM) cell cytomorphology, an important cornerstone of hematological diagnosis, is still done manually thousands of times every day because of a lack of data sets and trained models. We applied convolutional neural networks (CNNs) to a large data set of 171 374 microscopic cytological images taken from BM smears from 945 patients diagnosed with a variety of hematological diseases. The data set is the largest expert-annotated pool of BM cytology images available in the literature. It allows us to train high-quality classifiers of leukocyte cytomorphology that identify a wide range of diagnostically relevant cell species with high precision and recall. Our CNNs outcompete previous feature-based approaches and provide a proof-of-concept for the classification problem of single BM cells. This study is a step toward automated evaluation of BM cell morphology using state-of-the-art image-classification algorithms. The underlying data set represents an educational resource, as well as a reference for future artificial intelligence–based approaches to BM cytomorphology.},
	language = {en},
	number = {20},
	urldate = {2024-10-22},
	journal = {Blood},
	author = {Matek, Christian and Krappe, Sebastian and Münzenmayer, Christian and Haferlach, Torsten and Marr, Carsten},
	month = nov,
	year = {2021},
	pages = {1917--1927},
	file = {PDF:C\:\\Users\\caomi\\Zotero\\storage\\ZQKS4ZVX\\Matek et al. - 2021 - Highly accurate differentiation of bone marrow cell morphologies using deep neural networks on a lar.pdf:application/pdf},
}

@misc{matek_human-level_2019,
	title = {Human-level recognition of blast cells in acute myeloid leukemia with convolutional neural networks},
	url = {http://biorxiv.org/lookup/doi/10.1101/564039},
	doi = {10.1101/564039},
	abstract = {Reliable recognition of malignant white blood cells is a key step in the diagnosis of hematologic malignancies such as Acute Myeloid Leukemia. Microscopic morphological examination of blood cells is usually performed by trained human examiners, making the process tedious, time-consuming and hard to standardise.},
	language = {en},
	urldate = {2024-10-22},
	author = {Matek, Christian and Schwarz, Simone and Spiekermann, Karsten and Marr, Carsten},
	month = feb,
	year = {2019},
	file = {PDF:C\:\\Users\\caomi\\Zotero\\storage\\69XZ5QQN\\Matek et al. - 2019 - Human-level recognition of blast cells in acute myeloid leukemia with convolutional neural networks.pdf:application/pdf},
}


